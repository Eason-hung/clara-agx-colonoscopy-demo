{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "import os\n",
    "\n",
    "%set_env KEY=nvidia_tlt\n",
    "%set_env GPU_INDEX=0\n",
    "%set_env USER_EXPERIMENT_DIR=/workspace/tlt-experiments/unet\n",
    "%set_env DATA_DOWNLOAD_DIR=/workspace/tlt-experiments/Kvasir-SEG-TLT\n",
    "\n",
    "# Set this path if you don't run the notebook from the samples directory.\n",
    "# %env NOTEBOOK_ROOT=~/tlt-samples/unet\n",
    "\n",
    "# Please define this local project directory that needs to be mapped to the TLT docker session.\n",
    "# The dataset expected to be present in $LOCAL_PROJECT_DIR/data, while the results for the steps\n",
    "# in this notebook will be stored at $LOCAL_PROJECT_DIR/unet\n",
    "# !PLEASE MAKE SURE TO UPDATE THIS PATH!.\n",
    "%env LOCAL_PROJECT_DIR=/raid/home/eason/Unet_training\n",
    "\n",
    "# !PLEASE MAKE SURE TO UPDATE THIS PATH!.\n",
    "# Point to the 'deps' folder in samples from where you are launching notebook inside unet folder.\n",
    "%env PROJECT_DIR=/raid/home/eason/Unet_training\n",
    "\n",
    "os.environ[\"LOCAL_DATA_DIR\"] = os.path.join(\n",
    "    os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()),\n",
    "    \"Kvasir-SEG-TLT\"\n",
    ")\n",
    "os.environ[\"LOCAL_EXPERIMENT_DIR\"] = os.path.join(\n",
    "    os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()),\n",
    "    \"unet\"\n",
    ")\n",
    "\n",
    "# The sample spec files are present in the same path as the downloaded samples.\n",
    "os.environ[\"LOCAL_SPECS_DIR\"] = os.path.join(\n",
    "    os.getenv(\"NOTEBOOK_ROOT\", os.getcwd()),\n",
    "    \"specs\"\n",
    ")\n",
    "%set_env SPECS_DIR=/workspace/tlt-experiments/examples/unet/specs\n",
    "\n",
    "! ls -l $LOCAL_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping up the local directories to the TLT docker.\n",
    "import json\n",
    "mounts_file = os.path.expanduser(\"~/.tlt_mounts.json\")\n",
    "\n",
    "# Define the dictionary with the mapped drives\n",
    "drive_map = {\n",
    "    \"Mounts\": [\n",
    "        # Mapping the data directory\n",
    "        {\n",
    "            \"source\": os.environ[\"LOCAL_PROJECT_DIR\"],\n",
    "            \"destination\": \"/workspace/tlt-experiments\"\n",
    "        },\n",
    "        # Mapping the specs directory.\n",
    "        {\n",
    "            \"source\": os.environ[\"LOCAL_SPECS_DIR\"],\n",
    "            \"destination\": os.environ[\"SPECS_DIR\"]\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Writing the mounts file.\n",
    "with open(mounts_file, \"w\") as mfile:\n",
    "    json.dump(drive_map, mfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing the TLT launcher <a class=\"anchor\" id=\"head-1\"></a>\n",
    "The TLT launcher is a python package distributed as a python wheel listed in the `nvidia-pyindex` python index. You may install the launcher by executing the following cell.\n",
    "\n",
    "Please note that TLT recommends users to run the TLT launcher in a virtual env with python 3.6.9. You may follow the instruction in this [page](https://virtualenvwrapper.readthedocs.io/en/latest/install.html) to set up a python virtual env using the `virtualenv` and `virtualenvwrapper` packages. Once you have setup virtualenvwrapper, please set the version of python to be used in the virtual env by using the `VIRTUALENVWRAPPER_PYTHON` variable. You may do so by running\n",
    "\n",
    "```sh\n",
    "export VIRTUALENVWRAPPER_PYTHON=/path/to/bin/python3.x\n",
    "```\n",
    "where x >= 6 and <= 8\n",
    "\n",
    "We recommend performing this step first and then launching the notebook from the virtual environment. In addition to installing TLT python package, please make sure of the following software requirements:\n",
    "* python >=3.6.9 < 3.8.x\n",
    "* docker-ce > 19.03.5\n",
    "* docker-API 1.40\n",
    "* nvidia-container-toolkit > 1.3.0-1\n",
    "* nvidia-container-runtime > 3.4.0-1\n",
    "* nvidia-docker2 > 2.5.0-1\n",
    "* nvidia-driver > 455+\n",
    "\n",
    "Once you have installed the pre-requisites, please log in to the docker registry nvcr.io by following the command below\n",
    "\n",
    "```sh\n",
    "docker login nvcr.io\n",
    "```\n",
    "\n",
    "You will be trigerred to enter a username and password. The username is `$oauthtoken` and the password is the API key generated from `ngc.nvidia.com`. Please follow the instructions in the [NGC setup guide](https://docs.nvidia.com/ngc/ngc-overview/index.html#generating-api-key) to generate your own API key.\n",
    "\n",
    "Please note that TLT recommends users to run the TLT launcher in a virtual env with python >=3.6.9. You may follow the instruction in this [page](https://virtualenvwrapper.readthedocs.io/en/latest/install.html) to set up a python virtual env using the virtualenv and virtualenvwrapper packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP this step IF you have already installed the tlt launcher.\n",
    "!pip3 install nvidia-pyindex\n",
    "!pip3 install nvidia-tlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the versions of the TLT launcher\n",
    "!tlt info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use NGC CLI to get the pre-trained models. For more details, go to ngc.nvidia.com and click the SETUP on the navigation bar. \n",
    "\n",
    "*Note: When using vanilla_unet as arch for binary segmentation, pre-trained model section can be skipped. Pre-trained weights are available only for Resnet/ VGG templates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing NGC CLI on the local machine.\n",
    "## Download and install\n",
    "%env CLI=ngccli_reg_linux.zip\n",
    "!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n",
    "\n",
    "# Remove any previously existing CLI installations\n",
    "!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n",
    "!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n",
    "!unzip -u \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n",
    "!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model list nvidia/tlt_semantic_segmentation:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/pretrained_resnet101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull pretrained model from NGC\n",
    "!ngc registry model download-version nvidia/tlt_semantic_segmentation:resnet101 --dest $LOCAL_EXPERIMENT_DIR/pretrained_resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $LOCAL_EXPERIMENT_DIR/pretrained_resnet101/tlt_semantic_segmentation_vresnet101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Provide training specification <a class=\"anchor\" id=\"head-3\"></a>\n",
    "\n",
    "* Images and Masks path\n",
    "    * In order to use the newly generated images, masks folder update the dataset_config parameter in the spec file at `$SPECS_DIR/unet_train_resnet_unet_Kvasir_SEG.txt` \n",
    "    * Update the train, val images and masks paths. The test only requires the images path. \n",
    "* Pre-trained models\n",
    "* Augmentation parameters for on the fly data augmentation\n",
    "* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat $LOCAL_SPECS_DIR/unet_train_resnet_unet_Kvasir_SEG.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run TLT training <a class=\"anchor\" id=\"head-4\"></a>\n",
    "* Provide the sample spec file and the output directory location for models\n",
    "* WARNING: training will take several hours or one day to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"For multi-GPU, change --gpus based on your machine.\")\n",
    "!tlt unet train --gpus=1 --gpu_index=$GPU_INDEX \\\n",
    "              -e $SPECS_DIR/unet_train_resnet_unet_Kvasir_SEG.txt \\\n",
    "              -r $USER_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned \\\n",
    "              -m $USER_EXPERIMENT_DIR/pretrained_resnet101/tlt_semantic_segmentation_vresnet101/resnet_101.hdf5 \\\n",
    "              -n model_Kvasir_SEG \\\n",
    "              -k $KEY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet supports restarting from checkpoint. Incase, the training job is killed prematurely, you may resume training from the closest checkpoint by simply re-running the same command line. Please do make sure to use the same number of GPUs when restarting the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model for every epoch at checkpoint_interval mentioned in the spec file:')\n",
    "print('---------------------')\n",
    "!ls -ltrh $LOCAL_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/\n",
    "!ls -ltrh $LOCAL_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step model saved in the `$USER_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/weights` dir is used for evaluation/ inference/ export. The evaluation also creates `$LOCAL_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/results_tlt.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tlt unet evaluate --gpu_index=$GPU_INDEX -e $SPECS_DIR/unet_train_resnet_unet_Kvasir_SEG.txt \\\n",
    "                 -m $USER_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/weights/model_Kvasir_SEG.tlt \\\n",
    "                 -o $USER_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/ \\\n",
    "                 -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $LOCAL_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/results_tlt.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Export <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tlt-export will fail if .etlt already exists. So we clear the export folder before tlt-export\n",
    "!rm -rf $LOCAL_EXPERIMENT_DIR/export\n",
    "# Export in FP32 mode. \n",
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/export \n",
    "!tlt unet export --gpu_index=$GPU_INDEX -m $USER_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/weights/model_Kvasir_SEG.tlt \\\n",
    "               -k $KEY \\\n",
    "               -e $SPECS_DIR/unet_train_resnet_unet_Kvasir_SEG.txt \\\n",
    "               --data_type fp32 \\\n",
    "               --engine_file $USER_EXPERIMENT_DIR/export/trtfp32.Kvasir_SEG.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the tensorrt engine accuracy on the validation dataset. This generates results text file results_trt.json in \n",
    "# the dir mentioned to -o argument \n",
    "\n",
    "!tlt unet evaluate --gpu_index=$GPU_INDEX -e $SPECS_DIR/unet_train_resnet_unet_Kvasir_SEG.txt \\\n",
    "                 -m $USER_EXPERIMENT_DIR/export/trtfp32.Kvasir_SEG.engine \\\n",
    "                 -o $USER_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/ \\\n",
    "                 -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat $LOCAL_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/results_trt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $LOCAL_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/weights/*.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export in INt8 mode. \n",
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/export \n",
    "!tlt unet export --gpu_index=$GPU_INDEX -m $USER_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/weights/model_Kvasir_SEG.tlt \\\n",
    "                -k $KEY \\\n",
    "                -e $SPECS_DIR/unet_train_resnet_unet_Kvasir_SEG.txt \\\n",
    "                --data_type int8 \\\n",
    "                --engine_file $USER_EXPERIMENT_DIR/export/int8.Kvasir_SEG.engine \\\n",
    "                --data_type int8 \\\n",
    "                --cal_data_file $USER_EXPERIMENT_DIR/export/Kvasir_SEG_cal_data_file.txt \\\n",
    "                --cal_cache_file $USER_EXPERIMENT_DIR/export/Kvasir_SEG_cal.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if etlt model is correctly saved.\n",
    "!ls -l $LOCAL_EXPERIMENT_DIR/Kvasir_SEG_experiment_unpruned/weights/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
